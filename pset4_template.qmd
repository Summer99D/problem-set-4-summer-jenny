---
title: "Jenny and Summer PS4"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

1. This problem set is a paired problem set.
2. Play paper, scissors, rock to determine who goes first. Call that person Partner 1.
• Partner 1 (name and cnet ID): Jenny Zhong jzhong1
• Partner 2 (name and cnet ID): Summer Negahdar samarneg5
3. Partner 1 will accept the ps4 and then share the link it creates with their partner.
You can only share it with one partner so you will not be able to change it after your
partner has accepted.
4. “This submission is our work alone and complies with the 30538 integrity policy.” Add
your initials to indicate your agreement: **SN** **JZ**
5. “I have uploaded the names of anyone else other than my partner and I worked with
on the problem set here” (1 point)
6. Late coins used this pset: **__** Late coins left after submission: **__**
7. Knit your ps4.qmd to an PDF file to make ps4.pdf,
• The PDF should not be more than 25 pages. Use head() and re-size figures when
appropriate.
8. (Partner 1): push ps4.qmd and ps4.pdf to your github repo.
9. (Partner 1): submit ps4.pdf via Gradescope. Add your partner on Gradescope.
10. (Partner 1): tag your submission in Gradescope

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 
We use (`*`) to indicate a problem that we think might be time consuming. 
    
## Style Points (10 pts) 
Please refer to the minilesson on code style
**[here](https://uchicago.zoom.us/rec/share/pG_wQ-pHTQrJTmqNn4rcrw5V194M2H2s-2jdy8oVhWHkd_yZt9o162IWurpA-fxU.BIQlSgZLRYctvzp-)**.

## Submission Steps (10 pts)
1. This problem set is a paired problem set.
2. Play paper, scissors, rock to determine who goes first. Call that person *Partner 1*.
    - Partner 1 (name and cnet ID):
    - Partner 2 (name and cnet ID):
3. Partner 1 will accept the `ps4` and then share the link it creates with their partner. You can only share it with one partner so you will not be able to change it after your partner has accepted. 
4. "This submission is our work alone and complies with the 30538 integrity policy." Add your initials to indicate your agreement: \*\*\_\_\*\* \*\*\_\_\*\*
5. "I have uploaded the names of anyone else other than my partner and I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  (1 point)
6. Late coins used this pset: \*\*\_\_\*\* Late coins left after submission: \*\*\_\_\*\*
7. Knit your `ps4.qmd` to an PDF file to make `ps4.pdf`, 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
8. (Partner 1): push  `ps4.qmd` and `ps4.pdf` to your github repo.
9. (Partner 1): submit `ps4.pdf` via Gradescope. Add your partner on Gradescope.
10. (Partner 1): tag your submission in Gradescope

**Important:** Repositories are for tracking code. **Do not commit the data or shapefiles to your repo.** The best way to do this is with `.gitignore`, which we have covered in class. If you do accidentally commit the data, Github has a [guide](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github#removing-files-from-a-repositorys-history). The best course of action depends on whether you have pushed yet. This also means that both partners will have to download the initial raw data and any data cleaning code will need to be re-run on both partners' computers. 

## Download and explore the Provider of Services (POS) file (10 pts)

1. The variables that I pulled are: 
PRVDR_CTGRY_SBTYP_CD: subtype. Identifies the subtype of the provider, within the primary category. Used in reporting to show the breakdown of provider categories, mainly for hospitals and SNFs.

PRVDR_CTGRY_CD: provider category. Identifies the type of provider participating in the Medicare/Medicaid program.

PGM_TRMNTN_CD: termination code. Indicates the provider’s current termination status.

TRMNTN_EXPRTN_DT: Termination or Expiration Date. Date the provider was terminated. For CLIA providers, date the laboratory's certificate was terminated or the expiration date of the current CLIA certificate.

FAC_NAME: Facility / hospital name. Name of the provider certified to participate in the Medicare and/or Medicaid programs.

ZIP_CD: Zip code. Five-digit ZIP code for a provider's physical address.

CHOW_CNT: CHOW Count. Number of times this provider has changed ownership.

CHOW_DT: CHOW Date. Effective date of the most recent change of ownership for this provider.

CITY_NAME: City. City in which the provider is physically located.

PRVDR_NUM: CMS number/Provider number. Six or ten position identification number that is assigned to a certified provider. This is the CMS Certification Number.

2. 
```{python}
import pandas as pd
import geopandas as gpd
import shapely
import altair as alt
import sys
import pyproj
import os
from pyproj import CRS, Transformer

os.chdir('/Users/jennyzhong/Documents/GitHub/problem-set-4-summer-jenny/')

pos2016 = pd.read_csv('pos2016.csv')

pos2016.head(10)
```

```{python}
#converting to string
pos2016['PRVDR_CTGRY_SBTYP_CD'] = pos2016['PRVDR_CTGRY_SBTYP_CD'].astype(str).str.zfill(2)

pos2016['PRVDR_CTGRY_CD'] = pos2016['PRVDR_CTGRY_CD'].astype(str).str.zfill(2)
pos2016.head()
```

```{python}
st_hospitals2016 = pos2016[(pos2016['PRVDR_CTGRY_SBTYP_CD'] == '1.0') & (pos2016['PRVDR_CTGRY_CD'] == '01')]

print(st_hospitals2016.head())
st_hospitals2016.shape
```

a. 7,245 hospitals are reported in this data. 

b. Compared to sources that provide counts of short-term hospitals in the US, such as the Kaiser Family Foundation, we know that there were nearly 5,000 short term, acute care hospitals in the US in recent years (half of which are rural and half urban). This could be higher than the reported number because of definition differences, for example the dataset could define short-term hospitals different to the Kaiser Family Foundation's definition. 

adding the year 2016
```{python}
st_hospitals2016.loc[:, 'YEAR'] = 2016

print(st_hospitals2016)
```

3. 
for 2017: 
```{python}
#importing pos2017
pos2017 = pd.read_csv('pos2017.csv', encoding='latin1')
```

```{python}
#converting to string
pos2017['PRVDR_CTGRY_SBTYP_CD'] = pos2017['PRVDR_CTGRY_SBTYP_CD'].astype(str).str.zfill(2)

pos2017['PRVDR_CTGRY_CD'] = pos2017['PRVDR_CTGRY_CD'].astype(str).str.zfill(2)
pos2017.head()
```

```{python}
#then focus on st hospitals 
st_hospitals2017 = pos2017[(pos2017['PRVDR_CTGRY_SBTYP_CD'] == '1.0') & (pos2017['PRVDR_CTGRY_CD'] == '01')]

print(st_hospitals2017.head())
print(st_hospitals2017.tail())
st_hospitals2017.shape
```

Adding the 2017 column 
```{python}
st_hospitals2017.loc[:, 'YEAR'] = 2017

print(st_hospitals2017.head())
```

for 2018: 
```{python}
#importing pos2018

pos2018 = pd.read_csv('pos2018.csv',encoding='latin1')
```

```{python}
#converting to string
pos2018['PRVDR_CTGRY_SBTYP_CD'] = pos2018['PRVDR_CTGRY_SBTYP_CD'].astype(str).str.zfill(2)

pos2018['PRVDR_CTGRY_CD'] = pos2018['PRVDR_CTGRY_CD'].astype(str).str.zfill(2)
pos2018.head(5)
```

```{python}
#then focus on st hospitals 
st_hospitals2018 = pos2018[(pos2018['PRVDR_CTGRY_SBTYP_CD'] == '1.0') & (pos2018['PRVDR_CTGRY_CD'] == '01')]

print(st_hospitals2018.head(5))
print(st_hospitals2018.tail(5))
st_hospitals2018.shape
```

Adding the 2018 column 
```{python}
#column had to be extended
st_hospitals2018.loc[:, 'YEAR'] = 2018

print(st_hospitals2018.head(5))
```


for 2019: 
```{python}
pos2019 = pd.read_csv('pos2019.csv', encoding='latin1')
```

```{python}
#converting to string
pos2019['PRVDR_CTGRY_SBTYP_CD'] = pos2019['PRVDR_CTGRY_SBTYP_CD'].astype(str).str.zfill(2)

pos2019['PRVDR_CTGRY_CD'] = pos2019['PRVDR_CTGRY_CD'].astype(str).str.zfill(2)
pos2019.head(5)
```

```{python}
#then focus on st hospitals 
st_hospitals2019 = pos2019[(pos2019['PRVDR_CTGRY_SBTYP_CD'] == '1.0') & (pos2019['PRVDR_CTGRY_CD'] == '01')]

print(st_hospitals2019.head(5))
print(st_hospitals2019.tail(5))
st_hospitals2019.shape
```

Adding the 2019 column 
```{python}
st_hospitals2019.loc[:, 'YEAR'] = 2019

print(st_hospitals2019)
```

**Appending them together**
```{python}
all_years_data = pd.concat([st_hospitals2016, st_hospitals2017, st_hospitals2018, st_hospitals2019], ignore_index=True)

print(all_years_data.head())
all_years_data.shape
```

**Plotting by observations**
```{python}
observations_by_year = all_years_data.groupby('YEAR').size().reset_index(name='count')

chart13 = alt.Chart(observations_by_year).mark_bar().encode(
    x=alt.X('YEAR:O', title='Year'),
    y=alt.Y('count:Q', title='Number of Observations')  
).properties(
    title='Number of Observations by Year'
)
chart13.display()
```

4. 
    a.
```{python}
unique_hospitals_by_year = all_years_data.groupby('YEAR')['PRVDR_NUM'].nunique().reset_index(name='unique_count')

unique_hospital_chart = alt.Chart(unique_hospitals_by_year).mark_bar().encode(
    x=alt.X('YEAR:O', title='Year'),
    y=alt.Y('unique_count:Q', title='Number of Unique Hospitals') 
).properties(
    title='Number of Unique Hospitals by Year'
)

unique_hospital_chart.display()
```

b. The number of unique hospitals and total observations charts are identical, which means that each hospital has only one record in the dataset for each year. The dataset is structured as a snapshot of unique hospitals, with no intra-year variations or multiple records per hospital within each year. 

## Identify hospital closures in POS file (15 pts) (*)

1. 
2. 
3. 
    a.
    b.
    c.

## Download Census zip code shapefile (10 pt) 

1. 
    a. There are five types of file types here. 
**.shp (shape file)**: file contains the geometric shapes. It stores the spatial coordinates and shapes of objects like points, lines or polygons. 
**.shx (shape index format)**: file is an index of the geometry in the .shp file, and provides quick access to the geometric shapes. 
**.dbf (attribute format)**: file contains attribute data in tabular format, with each row corresponding to a feature and each column containing attributes associated with that feature. 
**.prj (projection format)**: file contains information about the coordinate sysetm and projection, and defines how shapes are mapped onto Earth's surface. 
**.xml (metadata format)**: file contains metadata, contains descriptive information about dataset such as source, creation date, projection dates. 

    b. 
| File Extension | Size (MB)  |
|----------------|------------|
| .shp           | 837.5      |
| .dbf           | 6.4        |
| .prj           | 0.000165   |
| .shx           | 0.000265   |
| .xml           | 0.016      |

2. 

<<<<<<< HEAD
```{python}
import geopandas as gpd
```

2. 
```{python}
shapefile_path = './gz_2010_us_860_00_500k/gz_2010_us_860_00_500k.shp'

try:
    zip_shapes = gpd.read_file(shapefile_path)
    print("Shapefile loaded successfully with SHX restoration.")
except Exception as e:
    print("Error loading shapefile:", e)
```

```{python}
#filtering for texas zip codes
texas_zip_shapes = zip_shapes[zip_shapes['ZCTA5'].astype(str).str.startswith(('75', '76', '77', '78', '79')) | (zip_shapes['ZCTA5'] == '733')]

print(texas_zip_shapes.head())
print("Number of Texas ZIP codes:", texas_zip_shapes.shape[0])
```

```{python}
#pos2016 
pos2016['ZIP_CD'] = pos2016['ZIP_CD'].astype(str)

texas_hospitals_2016 = pos2016[pos2016['ZIP_CD'].str.startswith(('75', '76', '77', '78', '79')) | (pos2016['ZIP_CD'] == '733')]

print(texas_hospitals_2016.head())
print("Number of Texas hospital records in 2016:", texas_hospitals_2016.shape[0])
```

```{python}
#counting the number of hospitals per ZIP code:
hospitals_per_zip = texas_hospitals_2016.groupby('ZIP_CD').size().reset_index(name='hospital_count')
```

```{python}
#merging for chloropleth mapping
texas_zip_shapes.loc[:, 'ZCTA5'] = texas_zip_shapes['ZCTA5'].astype(str)
hospitals_per_zip['ZIP_CD'] = hospitals_per_zip['ZIP_CD'].astype(str)

# convert ZIP_CD to integer, then to string with zero-padding to ensure 5-digit format
hospitals_per_zip['ZIP_CD'] = hospitals_per_zip['ZIP_CD'].astype(float).astype(int).astype(str).str.zfill(5)

# re-check the formatting
print("Formatted ZIP codes in hospitals_per_zip:", hospitals_per_zip['ZIP_CD'].unique()[:10])

# now, re-run the merge
texas_zip_shapes = texas_zip_shapes.merge(hospitals_per_zip, left_on='ZCTA5', right_on='ZIP_CD', how='left')

# fill NaN values in 'hospital_count' with 0 for ZIP codes with no hospitals
texas_zip_shapes['hospital_count'] = texas_zip_shapes['hospital_count'].fillna(0)

# Verify the number of common ZIP codes and non-zero hospital counts
print("Number of ZIP codes with hospital_count as 0:", (texas_zip_shapes['hospital_count'] == 0).sum())
print("Total ZIP codes in Texas:", texas_zip_shapes.shape[0])
print(texas_zip_shapes[['ZCTA5', 'hospital_count']].head(10))

```

```{python}
# Adjust the merge by specifying suffixes to handle duplicate columns
texas_zip_shapes = texas_zip_shapes.merge(
    hospitals_per_zip, 
    left_on='ZCTA5', 
    right_on='ZIP_CD', 
    how='left', 
    suffixes=('', '_y')  # Prevents '_x' and '_y' conflicts
)

# Drop any unnecessary duplicate columns that may arise
texas_zip_shapes = texas_zip_shapes.drop(columns=['ZIP_CD_y'], errors='ignore')

# Fill NaN values in 'hospital_count' with 0 for ZIP codes with no hospitals
texas_zip_shapes['hospital_count'] = texas_zip_shapes['hospital_count'].fillna(0)

# Verify the result
print("Number of ZIP codes with hospital_count as 0:", (texas_zip_shapes['hospital_count'] == 0).sum())
print("Total ZIP codes in Texas:", texas_zip_shapes.shape[0])
print(texas_zip_shapes[['ZCTA5', 'hospital_count']].head(10))
```

```{python}

import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, 1, figsize=(12, 10))
texas_zip_shapes.plot(column='hospital_count', cmap='OrRd', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)
ax.set_title("Number of Hospitals per ZIP Code in Texas (2016)")
ax.set_axis_off()
plt.show()
```


## Calculate zip code’s distance to the nearest hospital (20 pts) (*)

1. 
2. 
3. 
4. 
    a.
    b.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
2. 
3. 
4. 

## Reflecting on the exercise (10 pts) 
